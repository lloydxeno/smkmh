
library(dynamite)
timing <- system.time({
  smk_dep_females_fit <- dynamite(
    dformula = model_formula,
    data = lim_data_long_females,
    time = "year",
    group = "PUBID_1997",
    chains = 5,
    parallel_chains = 5,
    threads_per_chain = 3,  # 5*3=15 cores
    iter = 8000,
    warmup = 4000,
    thin = 1,
    refresh = 100,
    priors = required_priors_female,
    control = list(adapt_delta = 0.99, max_treedepth = 15)
  )
  
})
save.image("smk_status_dep_modeling_females.RData")

####Diagnostics
library(bayesplot)

fit_stan <- smk_dep_females_fit$stanfit

# List all parameter names
param_names <- dimnames(as.array(fit_stan))[[3]]
param_names[1:50]  # show first 50


mcmc_trace(fit_stan, pars = c("a_smkstat"))

#Identify the worst ESS 
library(bayesplot)
library(posterior)

trace_grid_worst <- function(fit, n_show = 9, rhat_thresh = 1.05, ess_thresh = 100) {
  # Extract Stan fit from dynamite object if needed
  fit_stan <- if ("stanfit" %in% names(fit)) fit$stanfit else fit
  
  # Summarize draws
  summ <- summarize_draws(fit_stan)
  
  # Exclude deterministic parameters (NA ESS or R-hat)
  summ_filtered <- subset(summ, !is.na(rhat) & !is.na(ess_bulk))
  
  # Identify problematic parameters
  problem_params <- subset(
    summ_filtered,
    rhat > rhat_thresh | ess_bulk < ess_thresh | ess_tail < ess_thresh
  )
  
  if (nrow(problem_params) == 0) {
    message("No stochastic parameters exceed diagnostic thresholds.")
    return(invisible(NULL))
  }
  
  # Order by worst R-hat first, then lowest bulk ESS
  problem_params <- problem_params[order(-problem_params$rhat, problem_params$ess_bulk), ]
  
  # Get top N parameters
  top_vars <- head(problem_params$variable, n_show)
  message("Top problematic parameters (stochastic only):")
  print(problem_params[1:min(n_show, nrow(problem_params)), 
                       c("variable", "rhat", "ess_bulk", "ess_tail")])
  
  # Trace plot grid
  mcmc_trace(fit_stan, pars = top_vars, facet_args = list(ncol = 3))
}

trace_grid_worst(smk_dep_females_fit, n_show = 9)
# 
# Top problematic parameters:
#   # A tibble: 8 Ã— 4
#   variable             rhat ess_bulk ess_tail
# <chr>               <dbl>    <dbl>    <dbl>
#   1 L_nu[2,1]            1.05     104.     440.
# 2 L_nu[2,2]            1.05     104.     440.
# 3 corr_matrix_nu[2,1]  1.05     104.     440.
# 4 corr_matrix_nu[1,2]  1.05     104.     440.
# 5 corr_nu[1]           1.05     104.     440.
# 6 L_nu[1,1]           NA         NA       NA 
# 7 L_nu[1,2]           NA         NA       NA 
# 8 corr_matrix_nu[1,1] NA         NA       NA 

#Tune the priors:
priors_tuned <- required_priors_female

# 1. Update sigma_nu priors to half-normal(0, 1)
priors_tuned$prior[priors_tuned$type == "sigma_nu"] <- "normal(0, 1) T[0,]"

# 2. Update the correlation matrix prior to LKJ(3)
# This assumes your correlation is called corr_matrix_nu or similar in the model
priors_tuned$prior[priors_tuned$type == "correlation"] <- "lkj_corr(3)"


smk_dep_females_fit_tuned <- dynamite(
  dformula = model_formula,
  data = lim_data_long_females,
  time = "year",
  group = "PUBID_1997",
  chains = 6,               # Increase chains to improve total ESS
  parallel_chains = 6,
  threads_per_chain = 1,
  iter = 12000,             # 6k warmup + 6k post-warmup
  warmup = 6000,
  thin = 1,
  refresh = 200,
  priors = priors_tuned,
  control = list(adapt_delta = 0.99, max_treedepth = 15)
)

###Need to fix the priors
# 1. Half-normal(0, 0.5) for sigma_nu
priors_tuned$prior[priors_tuned$type == "sigma_nu"] <- "normal(0, 0.5) T[0,]"

# 2. LKJ(4) for the Cholesky factor of the correlation matrix
# Replace lkj_corr_cholesky(1) with lkj_corr_cholesky(4)
priors_tuned$prior[priors_tuned$type == "L"] <- "lkj_corr_cholesky(4)"

# Check the updated priors
priors_tuned


#Fit again
smk_dep_females_fit_tuned <- dynamite(
  dformula = model_formula,
  data = lim_data_long_females,
  time = "year",
  group = "PUBID_1997",
  chains = 8,
  parallel_chains = 8,
  threads_per_chain = 1,
  iter = 12000,       # 6k warmup + 6k post-warmup
  warmup = 6000,
  thin = 1,
  refresh = 200,
  priors = priors_tuned,
  control = list(adapt_delta = 0.99, max_treedepth = 15)
)


trace_grid_worst(smk_dep_females_fit_tuned, n_show = 9)

#OK

#############################Build a Prediction Model for CESD 2019 depression##################
#############################Using the Random MH and Smoking Intercepts#########################


#Extract random effects per person

library(dynamite)

#Retrieve parameter names because Stan 
#calls them something else
param_names
grep("nu_", param_names, value = TRUE)
grep("nu_mh", param_names, value = TRUE)

library(dplyr)
library(tidyr)
library(stringr)
library(posterior)

draws <- as_draws_df(smk_dep_females_fit_tuned$stanfit)

# 1) Make an index -> PUBID map in the SAME order used by the model data
idx_map <- lim_data_long_females %>%
  distinct(PUBID_1997) %>%
  mutate(i = row_number())   # i = person index used in Stan

# 2) Extract first index i from parameter names like "nu_smkstat[123,1]"
ri_smk <- draws %>%
  select(starts_with("nu_smkstat[")) %>%
  summarise(across(everything(), mean)) %>%
  pivot_longer(everything(), names_to = "param", values_to = "ri_smk") %>%
  mutate(i = as.integer(str_extract(param, "(?<=\\[)\\d+"))) %>%
  select(i, ri_smk) %>%
  inner_join(idx_map, by = "i") %>%
  select(PUBID_1997, ri_smk)

ri_mh <- draws %>%
  select(starts_with("nu_mh5[")) %>%
  summarise(across(everything(), mean)) %>%
  pivot_longer(everything(), names_to = "param", values_to = "ri_mh") %>%
  mutate(i = as.integer(str_extract(param, "(?<=\\[)\\d+"))) %>%
  select(i, ri_mh) %>%
  inner_join(idx_map, by = "i") %>%
  select(PUBID_1997, ri_mh)

# 3) Join both effects
ri_both_effects <- ri_smk %>% inner_join(ri_mh, by = "PUBID_1997")

# 4) Merge the above with the lim_data_long_females

# Reduce to unique PUBID_1997 with fixed variables
fixed_vars <- lim_data_long_females %>%
  distinct(PUBID_1997, pct_peer_smk, age)

# Merge with random intercepts
ri_data_females <- ri_both_effects %>%
  inner_join(fixed_vars, by = "PUBID_1997")

# Check result
head(ri_data_females)
nrow(ri_data_females)  # should match number of unique PUBID_1997 in ri_both



#Export random intercepts and lim_data_long_females to another df to save disk space
save(ri_data_females,
     file = "ri_effects_females.RData")

#
load("C:/Users/llb296/OneDrive - University of Saskatchewan/Documents/Smk_Depression/ri_effects_females.RData")


#####Now import the CESD-19 scores
cesd_2019 <- read_dta("cesd_2019.dta")

library(dplyr)

ri_data_females <- ri_data_females %>%
  left_join(
    cesd_2019 %>% 
      select(PUBID_1997, CV_CESD_SCORE_R19_2019),
    by = "PUBID_1997"
  )

###Regression model
library(dplyr)

# Make sure data is complete for these variables
ri_data_females_clean <- ri_data_females %>%
  filter(!is.na(CV_CESD_SCORE_R19_2019))

# Fit linear regression
cesd_model_females <- lm(
  log(CV_CESD_SCORE_R19_2019 + 1) ~ ri_smk + ri_mh + pct_peer_smk + age,
  data = ri_data_females_clean
)

# View results
summary(cesd_model_females)


